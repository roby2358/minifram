# Round One
- get the chat interface working: websockets
- Get some sort of http access to your model: GLM local
- Get some sort of data store working: SQLite?
- Figure out the MCP protocol, what the models send and what they expect in response
  - MCP tool display/configuration in the UI
- Then wire it all together in a service (Python? Typescript? Rust?)
  - Multi-round LLM invocation

# Round Two
- Button to spin up a new agent in a separate tab
- "Contract" box to define work
- Logic for the model to iterate until it feels the contract is complete